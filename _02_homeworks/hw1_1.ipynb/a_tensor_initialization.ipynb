{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZN8RrekbILio"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.Tensor class\n",
        "\n",
        "t1=torch.Tensor([1,2,3],device='cpu')\n",
        "\n",
        "print(t1.dtype)          # 데이터타입 출력\n",
        "print(t1.device)         # 사용 자원 출력 (cpu/gpu)\n",
        "print(t1.requires_grad)  # 자동 미분 계산 여부\n",
        "print(t1.size())         # 텐서 사이즈 출력\n",
        "print(t1.shape)          # 텐서 모양 출력\n",
        "\n",
        "# t1을 cpu로 옮기는 작업\n",
        "# 현재 cpu내부에 텐서를 정의 하였기에 아무 효과 없음\n",
        "t1_cpu=t1.cpu()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQxFFa3SIUi6",
        "outputId": "25f3759f-e0f4-4549-e65d-7db641226564"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "cpu\n",
            "False\n",
            "torch.Size([3])\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.tensor class\n",
        "\n",
        "t2=torch.tensor([1,2,3],device='cpu')\n",
        "\n",
        "print(t2.dtype)         # 데이터타입 출력\n",
        "print(t2.device)        # 사용 자원 출력(cpu/gpu)\n",
        "print(t2.requires_grad) # 자동 미분 계산 여부\n",
        "print(t2.size())        # 텐서 사이즈 출력\n",
        "print(t2.shape)         # 텐서 모양 출력\n",
        "\n",
        "#t2를 cpu 내부로 옮기는 작업\n",
        "#현재 cpu 내부에 텐서를 정의하였기에 아무 효과 없음.\n",
        "t2_cpu=t2.cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86nj3SF2JLlU",
        "outputId": "fc7fea11-50ba-4d40-ebb4-9d5bf8fe77bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "cpu\n",
            "False\n",
            "torch.Size([3])\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1=torch.tensor(1)\n",
        "print(a1.shape,a1.ndim)\n",
        "\n",
        "a2=torch.tensor([1])\n",
        "print(a2.shape,a2.ndim)\n",
        "\n",
        "a3=torch.tensor([1,2,3,4,5])\n",
        "print(a3.shape,a3.ndim)\n",
        "\n",
        "a4=torch.tensor([[1],[2],[3],[4],[5]])\n",
        "print(a4.shape,a4.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1g5OSlKcjK",
        "outputId": "e7dff859-f262-4339-fdad-06fbefdfb0e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([]) 0\n",
            "torch.Size([1]) 1\n",
            "torch.Size([5]) 1\n",
            "torch.Size([5, 1]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a5=torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4],\n",
        "    [5,6]\n",
        "])\n",
        "print(a5.shape,a5.ndim)\n",
        "\n",
        "a6 = torch.tensor([\n",
        "    [[1], [2]],\n",
        "    [[3], [4]],\n",
        "    [[5], [6]]\n",
        "])\n",
        "print(a6.shape, a6.ndim)\n",
        "\n",
        "a7 = torch.tensor([\n",
        "    [[[1], [2]]],\n",
        "    [[[3], [4]]],\n",
        "    [[[5], [6]]]\n",
        "])\n",
        "print(a7.shape, a7.ndim)\n",
        "\n",
        "a8 = torch.tensor([\n",
        "    [[[1, 2, 3], [2, 3, 4]]],\n",
        "    [[[3, 1, 1], [4, 4, 5]]],\n",
        "    [[[5, 6, 2], [6, 3, 1]]]\n",
        "])\n",
        "print(a8.shape, a8.ndim)\n",
        "\n",
        "\n",
        "a9 = torch.tensor([\n",
        "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
        "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
        "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
        "])\n",
        "print(a9.shape, a9.ndim)\n",
        "\n",
        "a10 = torch.tensor([\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [1, 2, 3, 4, 5],\n",
        "])\n",
        "print(a10.shape, a10.ndim)\n",
        "\n",
        "a10 = torch.tensor([\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "    [[1, 2, 3, 4, 5]],\n",
        "])\n",
        "print(a10.shape, a10.ndim)\n",
        "\n",
        "# a11 = torch.tensor([\n",
        "#     [[[1, 2, 3], [4, 5]]],\n",
        "#     [[[1, 2, 3], [4, 5]]],\n",
        "#     [[[1, 2, 3], [4, 5]]],\n",
        "#     [[[1, 2, 3], [4, 5]]],\n",
        "# ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKRke3NlKk1A",
        "outputId": "1d390a83-266b-4e91-af5f-48e44221c45e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2]) 2\n",
            "torch.Size([3, 2, 1]) 3\n",
            "torch.Size([3, 1, 2, 1]) 4\n",
            "torch.Size([3, 1, 2, 3]) 4\n",
            "torch.Size([3, 1, 2, 3, 1]) 5\n",
            "torch.Size([4, 5]) 2\n",
            "torch.Size([4, 1, 5]) 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UX5St6GgLaVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}