{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17520, 17])\n",
      "torch.Size([17520, 18])\n",
      "tensor([ 1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
      "         0.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
      "         1.0000,  0.0000,  0.0000,  0.0000])\n",
      "data_size: 17497\n",
      "train_size: 17377, validation_size: 96, test_size: 24\n",
      "################################################## 1\n",
      "torch.Size([17377, 24, 18])\n",
      "torch.Size([17377, 24, 18]) torch.Size([17377])\n",
      "################################################## 2\n",
      "torch.Size([96, 24, 18]) torch.Size([96])\n",
      "################################################## 3\n",
      "torch.Size([24, 24, 18]) torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# 주피터 노트북에서는 __file__ 변수가 정의되지 않기에 직접 설정할 것임\n",
    "# BASE_PATH = str(Path(__file__).resolve().parent.parent.parent) # BASE_PATH: /Users/yhhan/git/link_dl\n",
    "\n",
    "\n",
    "# 본 과제 제출자는 현재 우분투 도커 환경에서 작업중이므로 다음과 같이 경로 설정\n",
    "BASE_PATH=\"/home/Deep-Learning-study\"\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "\n",
    "# 출력 옵셜 설정\n",
    "torch.set_printoptions(edgeitems=2, threshold=50, linewidth=75)\n",
    "\n",
    "# 데이터셋 경로 로드\n",
    "bikes_path = os.path.join(BASE_PATH, \"_00_data\", \"e_time-series-bike-sharing-dataset\", \"hour-fixed.csv\")\n",
    "\n",
    "# 1번째 열에서 일(day)추출하여 변환\n",
    "bikes_numpy = np.loadtxt(\n",
    "  fname=bikes_path, dtype=np.float32, delimiter=\",\", skiprows=1,\n",
    "  converters={\n",
    "    1: lambda x: float(x[8:10])  # 2011-01-07 --> 07 --> 7\n",
    "  }\n",
    ")\n",
    "\n",
    "\n",
    "# 넘파이 배열을 텐서로 변환 후 자료형은 float\n",
    "bikes_data = torch.from_numpy(bikes_numpy).to(torch.float)\n",
    "print(bikes_data.shape)    # >>> torch.Size([17520, 17])\n",
    "\n",
    "# 마지막 열을 분리\n",
    "bikes_target = bikes_data[:, -1].unsqueeze(dim=-1)  # 'cnt'\n",
    "# 마지막 열을 제외한 데이터를 원본에 저장\n",
    "bikes_data = bikes_data[:, :-1]   # >>> torch.Size([17520, 16])\n",
    "\n",
    "\n",
    "# 4*4 아이덴티티 메트릭스 생성\n",
    "eye_matrix = torch.eye(4)\n",
    "\n",
    "data_torch_list = []\n",
    "# 시간에 대해 처리\n",
    "for idx in range(bikes_data.shape[0]):  # range(730)\n",
    "  # 한시간지 데이터 추출\n",
    "  hour_data = bikes_data[idx]  # hour_data.shape: [17]\n",
    "  #원핫 벡터 코딩\n",
    "  weather_onehot = eye_matrix[hour_data[9].long() - 1]\n",
    "  # 원본 데이터와 원핫 벡터 데이터 결합\n",
    "  concat_data_torch = torch.cat(tensors=(hour_data, weather_onehot), dim=-1)\n",
    "  # concat_data_torch.shape: [20]\n",
    "  data_torch_list.append(concat_data_torch)\n",
    "\n",
    "\n",
    "# 하나의 텐서로 결합\n",
    "bikes_data = torch.stack(data_torch_list, dim=0)\n",
    "# 0번째 열 데이터와 9번쨰 열 데이터를 제외한 텐서 결합\n",
    "bikes_data = torch.cat([bikes_data[:, 1:9], bikes_data[:, 10:]], dim=-1)\n",
    "# Drop 'instant' and 'whethersit' columns\n",
    "\n",
    "print(bikes_data.shape)\n",
    "print(bikes_data[0])\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "sequence_size = 24\n",
    "validation_size = 96\n",
    "test_size = 24\n",
    "y_normalizer = 100\n",
    "\n",
    "# 데이터 사이즈 계산\n",
    "data_size = len(bikes_data) - sequence_size + 1\n",
    "print(\"data_size: {0}\".format(data_size))\n",
    "train_size = data_size - (validation_size + test_size)\n",
    "print(\"train_size: {0}, validation_size: {1}, test_size: {2}\".format(train_size, validation_size, test_size))\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "row_cursor = 0\n",
    "\n",
    "X_train_list = []\n",
    "y_train_regression_list = []\n",
    "for idx in range(0, train_size):\n",
    "  # 24시간 만큼 데이터 추출\n",
    "  sequence_data = bikes_data[idx: idx + sequence_size]\n",
    "  # 마지막 시간에 대한 타겟 추출\n",
    "  sequence_target = bikes_target[idx + sequence_size - 1]\n",
    "  X_train_list.append(sequence_data)\n",
    "  y_train_regression_list.append(sequence_target)\n",
    "  # 다음 시퀀스로 이동\n",
    "  row_cursor += 1\n",
    "\n",
    "X_train = torch.stack(X_train_list, dim=0).to(torch.float)\n",
    "print(X_train.shape)\n",
    "# 정규화 및 텐서로 변환\n",
    "y_train_regression = torch.tensor(y_train_regression_list, dtype=torch.float32) / y_normalizer\n",
    "\n",
    "# 평균 연산\n",
    "m = X_train.mean(dim=0, keepdim=True)\n",
    "# 표준 편차 연산\n",
    "s = X_train.std(dim=0, keepdim=True)\n",
    "# 정규화\n",
    "X_train = (X_train - m) / s\n",
    "\n",
    "print(X_train.shape, y_train_regression.shape)\n",
    "# >>> torch.Size([17376, 24, 19]) torch.Size([17376])\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "#################################################################################################\n",
    "\n",
    "X_validation_list = []\n",
    "y_validation_regression_list = []\n",
    "\n",
    "# validation 크기만큼 시퀀스\n",
    "# train데이터 가공과 과정 같음\n",
    "for idx in range(row_cursor, row_cursor + validation_size):\n",
    "  sequence_data = bikes_data[idx: idx + sequence_size]\n",
    "  sequence_target = bikes_target[idx + sequence_size - 1]\n",
    "  X_validation_list.append(sequence_data)\n",
    "  y_validation_regression_list.append(sequence_target)\n",
    "  row_cursor += 1\n",
    "\n",
    "X_validation = torch.stack(X_validation_list, dim=0).to(torch.float)\n",
    "y_validation_regression = torch.tensor(y_validation_regression_list, dtype=torch.float32) / y_normalizer\n",
    "\n",
    "X_validation = (X_validation - m) / s\n",
    "\n",
    "print(X_validation.shape, y_validation_regression.shape)\n",
    "# >>> torch.Size([96, 24, 19]) torch.Size([96])\n",
    "\n",
    "print(\"#\" * 50, 3)\n",
    "#################################################################################################\n",
    "\n",
    "# train 데이터 가공과 과정 동일\n",
    "X_test_list = []\n",
    "y_test_regression_list = []\n",
    "for idx in range(row_cursor, row_cursor + test_size):\n",
    "  sequence_data = bikes_data[idx: idx + sequence_size]\n",
    "  sequence_target = bikes_target[idx + sequence_size - 1]\n",
    "  X_test_list.append(sequence_data)\n",
    "  y_test_regression_list.append(sequence_target)\n",
    "  row_cursor += 1\n",
    "\n",
    "X_test = torch.stack(X_test_list, dim=0).to(torch.float)\n",
    "y_test_regression = torch.tensor(y_test_regression_list, dtype=torch.float32) / y_normalizer\n",
    "\n",
    "X_test -= (X_test - m) / s\n",
    "\n",
    "print(X_test.shape, y_test_regression.shape)\n",
    "# >>> torch.Size([24, 24, 18]) torch.Size([24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
