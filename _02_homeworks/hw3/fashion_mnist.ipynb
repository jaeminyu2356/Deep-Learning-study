{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 상수 정의 부분에 추가\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 본 과제 제출자는 현재 우분투 도커 환경에서 작업중이므로 다음과 같이 경로 설정\n",
    "BASE_PATH=\"/home/Deep-Learning-study\"\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "from _01_code._99_common_utils.utils import get_num_cpu_cores, is_linux, is_windows\n",
    "num_data_loading_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(train_loader):\n",
    "    \"\"\"\n",
    "    데이터셋의 mean과 std를 계산하는 함수\n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader): 학습 데이터셋의 DataLoader 객체\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mean, std) - 계산된 평균과 표준편차 값\n",
    "    \"\"\"\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images = 0\n",
    "    \n",
    "    print(\"Calculating dataset statistics...\")\n",
    "    print(\"This may take a moment...\")\n",
    "    \n",
    "    # Step 1: 평균(mean) 계산\n",
    "    for images, _ in train_loader:\n",
    "        # batch_samples: 현재 배치의 이미지 개수\n",
    "        batch_samples = images.size(0)\n",
    "        # images shape 변경: [batch_size, channels, height, width] -> [batch_size, channels, height*width]\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        # 각 채널별 평균 계산 후 배치의 합 누적\n",
    "        mean += images.mean(2).sum(0)  # dim=2는 height*width 차원에 대한 평균\n",
    "        total_images += batch_samples\n",
    "    \n",
    "    # 전체 이미지 수로 나누어 최종 평균 계산\n",
    "    mean /= total_images\n",
    "    \n",
    "    # Step 2: 분산(variance) 계산\n",
    "    var = 0.\n",
    "    for images, _ in train_loader:\n",
    "        batch_samples = images.size(0)\n",
    "        # 이미지 shape 변경\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        # 각 픽셀값에서 평균을 뺀 후 제곱하여 분산 계산\n",
    "        # mean.unsqueeze(1): mean을 [channels, 1]로 확장하여 broadcasting 가능하게 함\n",
    "        var += ((images - mean.unsqueeze(1))**2).sum([0,2])  # [0,2]는 batch와 height*width 차원\n",
    "    \n",
    "    # 표준편차 계산: 분산의 제곱근\n",
    "    # total_images * 28 * 28: 전체 픽셀 수\n",
    "    std = torch.sqrt(var / (total_images * 28 * 28))\n",
    "    \n",
    "    # 계산된 통계값 출력\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Number of training images: {total_images}\")\n",
    "    print(f\"Mean: {mean.item():.4f}\")  # .item()으로 텐서값을 파이썬 스칼라로 변환\n",
    "    print(f\"Std: {std.item():.4f}\")\n",
    "    print(f\"Var: {std.item()**2:.4f}\")\n",
    "    \n",
    "    # wandb에 계산된 통계값 기록 (wandb 실행 중일 때만)\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.summary.update({\n",
    "            \"dataset_mean\": mean.item(),\n",
    "            \"dataset_std\": std.item(),\n",
    "            \"dataset_variance\": std.item()**2\n",
    "        })\n",
    "    \n",
    "    return mean.item(), std.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_data():\n",
    "    \"\"\"\n",
    "    Fashion MNIST 데이터셋의 학습 및 검증용 데이터 로더를 생성하는 함수\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_data_loader, validation_data_loader, val_transform)\n",
    "            - train_data_loader: 학습용 데이터 로더\n",
    "            - validation_data_loader: 검증용 데이터 로더\n",
    "            - val_transform: 검증/테스트에 사용할 transform\n",
    "    \"\"\"\n",
    "    # 데이터셋 저장 경로 설정\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "\n",
    "    print(\"\\nLoading Fashion MNIST dataset...\")\n",
    "    \n",
    "    # Step 1: 통계 계산을 위한 초기 데이터셋 로드\n",
    "    # ToTensor()만 적용하여 픽셀값을 0~1 범위로 정규화\n",
    "    f_mnist_train = datasets.FashionMNIST(\n",
    "        data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    # Step 2: 데이터셋 통계(mean, std) 계산을 위한 임시 데이터 로더\n",
    "    # batch_size=1000으로 메모리 사용량 조절\n",
    "    temp_loader = DataLoader(\n",
    "        dataset=f_mnist_train,\n",
    "        batch_size=1000,\n",
    "        shuffle=False,  # 통계 계산시 순서 무관\n",
    "        num_workers=num_data_loading_workers  # 병렬 처리\n",
    "    )\n",
    "    \n",
    "    # Step 3: 데이터셋의 평균과 표준편차 계산\n",
    "    mean, std = calculate_mean_std(temp_loader)\n",
    "    \n",
    "    print(\"\\nApplying calculated normalization values:\")\n",
    "    print(f\"Mean: {mean:.4f}\")\n",
    "    print(f\"Std: {std:.4f}\")\n",
    "    \n",
    "    # Step 4: 학습용 transform 정의 (데이터 증강 포함)\n",
    "    train_transform = transforms.Compose([\n",
    "        # 50% 확률로 이미지 좌우 반전\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # ±10도 범위에서 랜덤 회전\n",
    "        transforms.RandomRotation(10),\n",
    "        # 이미지 변형: 이동 및 크기 조정\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,  # 추가 회전 없음\n",
    "            translate=(0.1, 0.1),  # 10% 범위 내 랜덤 이동\n",
    "            scale=(0.9, 1.1)  # 90%~110% 범위 내 크기 조정\n",
    "        ),\n",
    "        transforms.ToTensor(),  # PIL 이미지를 텐서로 변환\n",
    "        transforms.Normalize(mean=mean, std=std)  # 계산된 통계값으로 정규화\n",
    "    ])\n",
    "    \n",
    "    # Step 5: 검증용 transform 정의 (데이터 증강 제외)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    # Step 6: transform이 적용된 데이터셋 재생성\n",
    "    f_mnist_train = datasets.FashionMNIST(\n",
    "        data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    f_mnist_validation = datasets.FashionMNIST(\n",
    "        data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # Step 7: 학습/검증 데이터 분할\n",
    "    # 전체 60,000개 중 55,000개는 학습용, 5,000개는 검증용\n",
    "    train_indices = range(0, 55_000)\n",
    "    validation_indices = range(55_000, 60_000)\n",
    "\n",
    "    f_mnist_train = torch.utils.data.Subset(f_mnist_train, train_indices)\n",
    "    f_mnist_validation = torch.utils.data.Subset(f_mnist_validation, validation_indices)\n",
    "\n",
    "    # Step 8: DataLoader 생성\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=f_mnist_train,\n",
    "        batch_size=wandb.config.batch_size,\n",
    "        shuffle=True,  # 학습 시 데이터 순서 섞기\n",
    "        pin_memory=True,  # GPU 메모리 전송 최적화\n",
    "        num_workers=num_data_loading_workers  # 병렬 데이터 로딩\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=f_mnist_validation,\n",
    "        batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    # 데이터 로더와 검증용 transform 반환\n",
    "    return train_data_loader, validation_data_loader, val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_test_data(batch_size=128):\n",
    "    \"\"\"\n",
    "    Fashion MNIST 테스트 데이터셋을 위한 데이터 로더를 생성하는 함수\n",
    "    \n",
    "    Args:\n",
    "        batch_size (int): 배치 크기 (기본값: 128)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (f_mnist_test_images, test_data_loader, transform)\n",
    "            - f_mnist_test_images: 원본 테스트 이미지 (시각화용)\n",
    "            - test_data_loader: 정규화된 테스트 데이터 로더\n",
    "            - transform: 테스트 데이터에 적용된 transform\n",
    "    \"\"\"\n",
    "    # 데이터셋 저장 경로 설정\n",
    "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
    "    \n",
    "    # Step 1: 테스트용 transform 정의\n",
    "    # 데이터 증강은 제외하고 기본적인 정규화만 적용\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL 이미지를 텐서로 변환 (0~1 범위로 정규화)\n",
    "        transforms.Normalize(\n",
    "            mean=0.2860,  # 학습 데이터에서 계산된 평균값\n",
    "            std=0.3530    # 학습 데이터에서 계산된 표준편차값\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Step 2: 원본 테스트 이미지 로드 (시각화용)\n",
    "    # transform을 적용하지 않은 원본 상태로 저장\n",
    "    f_mnist_test_images = datasets.FashionMNIST(\n",
    "        data_path,        # 데이터 저장 경로\n",
    "        train=False,      # 테스트 데이터셋 사용\n",
    "        download=True     # 필요시 데이터 다운로드\n",
    "    )\n",
    "\n",
    "    # Step 3: 정규화된 테스트 데이터셋 생성\n",
    "    # 모델 평가에 사용할 정규화된 버전\n",
    "    f_mnist_test = datasets.FashionMNIST(\n",
    "        data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform  # 정규화 transform 적용\n",
    "    )\n",
    "\n",
    "    # Step 4: 테스트 데이터 로더 생성\n",
    "    test_data_loader = DataLoader(\n",
    "        dataset=f_mnist_test,\n",
    "        batch_size=batch_size,      # 지정된 배치 크기 사용\n",
    "        pin_memory=True,            # GPU 메모리 전송 최적화\n",
    "        num_workers=num_data_loading_workers  # 병렬 데이터 로딩\n",
    "    )\n",
    "\n",
    "    # 원본 이미지, 정규화된 데이터 로더, transform 반환\n",
    "    return f_mnist_test_images, test_data_loader, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험의 재현성을 위한 랜덤 시드 설정 함수\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"\n",
    "    모든 랜덤 생성기에 대한 시드를 설정하는 함수\n",
    "    \n",
    "    Args:\n",
    "        seed (int): 설정할 랜덤 시드 값 (기본값: 42)\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)          # PyTorch CPU 연산의 랜덤 시드 설정\n",
    "    torch.cuda.manual_seed_all(seed) # PyTorch GPU 연산의 랜덤 시드 설정\n",
    "    np.random.seed(seed)            # NumPy 랜덤 시드 설정\n",
    "    random.seed(seed)               # Python 기본 랜덤 시드 설정\n",
    "\n",
    "class FashionMNISTResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Fashion MNIST 데이터셋을 위해 수정된 ResNet18 모델\n",
    "    \n",
    "    특징:\n",
    "    - 그레이스케일 이미지 입력 처리 (1채널)\n",
    "    - 28x28 크기의 작은 이미지에 최적화\n",
    "    - 10개 클래스 분류를 위한 출력층\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        모델 구조 초기화\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # ImageNet으로 사전 학습된 ResNet18 모델 로드\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # 입력층 수정\n",
    "        # - in_channels=1: 그레이스케일 이미지 처리\n",
    "        # - out_channels=64: ResNet 구조 유지\n",
    "        # - kernel_size=3: 작은 이미지에 적합한 커널 크기\n",
    "        # - stride=1: 작은 이미지의 특징 보존\n",
    "        # - padding=1: 입력 크기 유지\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        # maxpool 레이어 제거\n",
    "        # - 28x28 크기의 작은 이미지에서는 초기 다운샘플링이 불필요\n",
    "        # - Identity()를 사용하여 입력을 그대로 통과\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        \n",
    "        # 출력층 수정\n",
    "        # - Dropout(0.5): 과적합 방지\n",
    "        # - Linear(..., 10): Fashion MNIST의 10개 클래스 출력\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # 50% 드롭아웃으로 과적합 방지\n",
    "            nn.Linear(self.model.fc.in_features, 10)  # 10개 클래스로 출력\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 연산 정의\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): 입력 이미지 배치\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: 각 클래스에 대한 예측 점수\n",
    "        \"\"\"\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    한 에포크 동안의 모델 학습을 수행하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): 학습할 모델\n",
    "        train_loader (DataLoader): 학습 데이터 로더\n",
    "        criterion: 손실 함수 (예: CrossEntropyLoss)\n",
    "        optimizer: 옵티마이저 (예: Adam)\n",
    "        device: 학습에 사용할 디바이스 (cuda 또는 cpu)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "            - average_loss (float): 에포크의 평균 손실값\n",
    "            - accuracy (float): 에포크의 정확도 (백분율)\n",
    "    \"\"\"\n",
    "    # 모델을 학습 모드로 설정\n",
    "    model.train()\n",
    "    \n",
    "    # 손실값과 정확도 계산을 위한 변수 초기화\n",
    "    running_loss = 0.0  # 누적 손실값\n",
    "    correct = 0         # 정확히 예측한 샘플 수\n",
    "    total = 0          # 전체 샘플 수\n",
    "    \n",
    "    # 미니배치 단위로 학습 수행\n",
    "    for inputs, labels in train_loader:\n",
    "        # 데이터를 지정된 디바이스로 이동\n",
    "        inputs = inputs.to(device)   # 입력 이미지\n",
    "        labels = labels.to(device)   # 정답 레이블\n",
    "        \n",
    "        # 1. 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. 순전파 (forward pass)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. 역전파 (backward pass)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계 업데이트\n",
    "        running_loss += loss.item()                      # 배치의 손실값 누적\n",
    "        _, predicted = outputs.max(1)                    # 가장 높은 확률의 클래스 선택\n",
    "        total += labels.size(0)                         # 배치 크기만큼 전체 개수 증가\n",
    "        correct += predicted.eq(labels).sum().item()    # 정확히 예측한 개수 계산\n",
    "    \n",
    "    # 평균 손실값과 정확도 반환\n",
    "    avg_loss = running_loss / len(train_loader)  # 전체 배치에 대한 평균 손실\n",
    "    accuracy = 100. * correct / total            # 정확도를 백분율로 계산\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    검증 데이터셋에서 모델의 성능을 평가하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): 평가할 모델\n",
    "        val_loader (DataLoader): 검증 데이터 로더\n",
    "        criterion: 손실 함수 (예: CrossEntropyLoss)\n",
    "        device: 평가에 사용할 디바이스 (cuda 또는 cpu)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "            - average_loss (float): 검증 세트의 평균 손실값\n",
    "            - accuracy (float): 검증 세트의 정확도 (백분율)\n",
    "    \"\"\"\n",
    "    # 모델을 평가 모드로 설정\n",
    "    # - dropout과 batch normalization이 평가 모드로 변경됨\n",
    "    model.eval()\n",
    "    \n",
    "    # 성능 측정을 위한 변수 초기화\n",
    "    running_loss = 0.0  # 누적 손실값\n",
    "    correct = 0         # 정확히 예측한 샘플 수\n",
    "    total = 0          # 전체 샘플 수\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    # - 검증 시에는 가중치 업데이트가 필요 없음\n",
    "    # - 메모리 사용량 감소 및 연산 속도 향상\n",
    "    with torch.no_grad():\n",
    "        # 미니배치 단위로 검증 수행\n",
    "        for inputs, labels in val_loader:\n",
    "            # 데이터를 지정된 디바이스로 이동\n",
    "            inputs = inputs.to(device)   # 입력 이미지\n",
    "            labels = labels.to(device)   # 정답 레이블\n",
    "            \n",
    "            # 1. 순전파 (forward pass)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 2. 손실 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 통계 업데이트\n",
    "            running_loss += loss.item()                      # 배치의 손실값 누적\n",
    "            _, predicted = outputs.max(1)                    # 가장 높은 확률의 클래스 선택\n",
    "            total += labels.size(0)                         # 배치 크기만큼 전체 개수 증가\n",
    "            correct += predicted.eq(labels).sum().item()    # 정확히 예측한 개수 계산\n",
    "    \n",
    "    # 평균 손실값과 정확도 반환\n",
    "    avg_loss = running_loss / len(val_loader)  # 전체 배치에 대한 평균 손실\n",
    "    accuracy = 100. * correct / total          # 정확도를 백분율로 계산\n",
    "    \n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device):\n",
    "    \"\"\"\n",
    "    학습이 완료된 모델의 최종 성능을 테스트 데이터셋에서 평가하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): 평가할 모델\n",
    "        device: 평가에 사용할 디바이스 (cuda 또는 cpu)\n",
    "    \n",
    "    Returns:\n",
    "        float: 테스트 데이터셋에 대한 정확도 (백분율)\n",
    "    \"\"\"\n",
    "    # 모델을 평가 모드로 설정\n",
    "    # - dropout과 batch normalization이 평가 모드로 변경됨\n",
    "    model.eval()\n",
    "    \n",
    "    # 테스트 데이터 로드\n",
    "    # - test_images: 원본 이미지 (시각화용)\n",
    "    # - test_loader: 정규화된 데이터 로더\n",
    "    # - _: transform (사용하지 않음)\n",
    "    test_images, test_loader, _ = get_fashion_mnist_test_data(batch_size=128)\n",
    "    \n",
    "    # 성능 측정을 위한 변수 초기화\n",
    "    correct = 0  # 정확히 예측한 샘플 수\n",
    "    total = 0    # 전체 샘플 수\n",
    "    \n",
    "    # 그래디언트 계산 비활성화\n",
    "    # - 테스트 시에는 가중치 업데이트가 필요 없음\n",
    "    # - 메모리 사용량 감소 및 연산 속도 향상\n",
    "    with torch.no_grad():\n",
    "        # 미니배치 단위로 테스트 수행\n",
    "        for images, labels in test_loader:\n",
    "            # 데이터를 지정된 디바이스로 이동\n",
    "            images = images.to(device)  # 입력 이미지\n",
    "            labels = labels.to(device)  # 정답 레이블\n",
    "            \n",
    "            # 모델 예측 수행\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 가장 높은 확률의 클래스 선택\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # 통계 업데이트\n",
    "            total += labels.size(0)                    # 배치 크기만큼 전체 개수 증가\n",
    "            correct += (predicted == labels).sum().item()  # 정확히 예측한 개수 계산\n",
    "    \n",
    "    # 최종 정확도 계산 (백분율)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # wandb에 테스트 결과 기록 (wandb 실행 중인 경우에만)\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.summary[\"test_accuracy\"] = test_accuracy\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fashion MNIST 분류 모델의 전체 학습 파이프라인을 관리하는 메인 함수\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: 학습된 모델\n",
    "    \"\"\"\n",
    "    # 재현성을 위한 랜덤 시드 설정\n",
    "    set_seed()\n",
    "    \n",
    "    # 학습에 사용할 디바이스 설정 (GPU/CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Step 1: wandb 설정\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        project=\"fashion-mnist-resnet\",\n",
    "        name=\"resnet18_fashion_mnist\",\n",
    "        config={\n",
    "            \"architecture\": \"ResNet18\",\n",
    "            \"learning_rate\": 1e-3,        # 초기 학습률\n",
    "            \"batch_size\": 128,            # 배치 크기\n",
    "            \"epochs\": 20,                 # 총 에포크 수\n",
    "            \"weight_decay\": 1e-4,         # L2 정규화 강도\n",
    "            \"early_stop_patience\": 7,      # 조기 종료 인내심\n",
    "            \"optimizer\": \"AdamW\",         # 사용할 옵티마이저\n",
    "            \"scheduler\": \"ReduceLROnPlateau\",  # 학습률 스케줄러\n",
    "            \"dataset\": \"Fashion MNIST\"     # 데이터셋 이름\n",
    "        }\n",
    "    )\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Step 2: 데이터 준비\n",
    "    train_loader, val_loader, transforms = get_fashion_mnist_data()\n",
    "    \n",
    "    # Step 3: 모델 초기화 및 설정\n",
    "    model = FashionMNISTResNet().to(device)\n",
    "    summary(model, input_size=(1, 1, 28, 28))  # 모델 구조 출력\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)  # wandb 모델 모니터링\n",
    "    \n",
    "    # Step 4: 학습 도구 설정\n",
    "    criterion = nn.CrossEntropyLoss()  # 손실 함수\n",
    "    optimizer = torch.optim.AdamW(     # 옵티마이저\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(  # 학습률 조정기\n",
    "        optimizer, mode='max', factor=0.1, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Step 5: wandb 진행 상황 테이블 설정\n",
    "    columns = [\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
    "    progress_table = wandb.Table(columns=columns)\n",
    "    \n",
    "    # Step 6: Early Stopping 초기화\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Step 7: 학습 루프\n",
    "    for epoch in range(config.epochs):\n",
    "        # 7.1 학습 단계\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # 7.2 검증 단계\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # 7.3 학습률 업데이트\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # 7.4 wandb 로깅\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc,\n",
    "            \"learning_rate\": current_lr\n",
    "        })\n",
    "        \n",
    "        # 7.5 진행 상황 출력\n",
    "        print(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {current_lr}\")\n",
    "        \n",
    "        # 7.6 Early Stopping 및 모델 저장\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # 최고 성능 모델 저장\n",
    "            model_path = os.path.join(wandb.run.dir, 'best_model.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "            }, model_path)\n",
    "            wandb.save('best_model.pth')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Early stopping 체크\n",
    "        if patience_counter >= config.early_stop_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # Step 8: 최종 결과 기록\n",
    "    wandb.run.summary[\"best_validation_accuracy\"] = best_val_acc\n",
    "    \n",
    "    # Step 9: 테스트 세트 평가\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_acc = test_model(model, device)\n",
    "    wandb.run.summary[\"test_accuracy\"] = test_acc\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, device, num_samples=10):\n",
    "    \"\"\"\n",
    "    테스트 데이터셋에서 모델의 예측 결과를 시각화하는 함수\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): 평가할 모델\n",
    "        device: 평가에 사용할 디바이스 (cuda 또는 cpu)\n",
    "        num_samples (int): 시각화할 샘플 수 (기본값: 10)\n",
    "    \n",
    "    특징:\n",
    "        - 최소 1개의 틀린 예측을 포함하여 시각화\n",
    "        - 나머지는 올바른 예측으로 구성\n",
    "        - 틀린 예측에 대한 상세 분석 제공\n",
    "    \"\"\"\n",
    "    # Step 1: 데이터 준비\n",
    "    test_images, test_loader, _ = get_fashion_mnist_test_data()\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    \n",
    "    # Step 2: 데이터 전처리를 위한 transform 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # PIL 이미지를 텐서로 변환\n",
    "        transforms.Normalize(mean=0.2860, std=0.3530)  # 학습 시와 동일한 정규화 적용\n",
    "    ])\n",
    "    \n",
    "    # Step 3: 틀린 예측과 올바른 예측 찾기\n",
    "    wrong_predictions = []    # 틀린 예측의 인덱스 저장\n",
    "    correct_predictions = []  # 올바른 예측의 인덱스 저장\n",
    "    \n",
    "    with torch.no_grad():  # 메모리 효율성을 위해 그래디언트 계산 비활성화\n",
    "        for idx in range(len(test_images)):\n",
    "            # 이미지 전처리 및 예측\n",
    "            image, label = test_images[idx]\n",
    "            image_tensor = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "            output = model(image_tensor)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "            \n",
    "            # 예측 결과에 따라 분류\n",
    "            if pred != label:\n",
    "                wrong_predictions.append(idx)\n",
    "            else:\n",
    "                correct_predictions.append(idx)\n",
    "            \n",
    "            # 충분한 틀린 예측을 찾으면 중단\n",
    "            if len(wrong_predictions) >= 3:\n",
    "                break\n",
    "    \n",
    "    # Step 4: 시각화할 샘플 선택\n",
    "    selected_indices = [wrong_predictions[0]]  # 틀린 예측 1개 포함\n",
    "    remaining_samples = num_samples - 1\n",
    "    selected_indices.extend(random.sample(correct_predictions, remaining_samples))\n",
    "    random.shuffle(selected_indices)  # 랜덤 순서로 배치\n",
    "    \n",
    "    # Step 5: 시각화\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2x5 그리드 생성\n",
    "    axes = axes.ravel()  # 2D 배열을 1D로 변환\n",
    "    \n",
    "    for idx, sample_idx in enumerate(selected_indices):\n",
    "        # 이미지 로드 및 예측\n",
    "        image, label = test_images[sample_idx]\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            pred = output.argmax(dim=1).item()\n",
    "        \n",
    "        # 이미지 및 예측 결과 표시\n",
    "        axes[idx].imshow(image, cmap='gray')\n",
    "        axes[idx].axis('off')\n",
    "        title = f'True: {class_names[label]}\\nPred: {class_names[pred]}'\n",
    "        color = 'green' if pred == label else 'red'\n",
    "        axes[idx].set_title(title, color=color)\n",
    "        \n",
    "        # 틀린 예측에 대한 상세 분석\n",
    "        if pred != label:\n",
    "            print(f\"\\n틀린 예측 분석:\")\n",
    "            print(f\"실제 클래스: {class_names[label]}\")\n",
    "            print(f\"예측 클래스: {class_names[pred]}\")\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 6: 시각화된 샘플들의 정확도 계산 및 출력\n",
    "    correct = sum(1 for idx in selected_indices if \n",
    "                 model(transform(test_images[idx][0]).unsqueeze(0).to(device)).argmax(dim=1).item() == test_images[idx][1])\n",
    "    print(f\"\\nVisualization Accuracy: {correct/num_samples*100:.2f}% ({correct}/{num_samples} correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/Deep-Learning-study/_02_homeworks/hw3/wandb/run-20241122_162611-4qmtqc3k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet/runs/4qmtqc3k' target=\"_blank\">resnet18_fashion_mnist</a></strong> to <a href='https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet' target=\"_blank\">https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet/runs/4qmtqc3k' target=\"_blank\">https://wandb.ai/jaeminyu2356-korea-university-of-technology-and-education/fashion-mnist-resnet/runs/4qmtqc3k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Fashion MNIST dataset...\n",
      "Calculating dataset statistics...\n",
      "This may take a moment...\n",
      "\n",
      "Dataset Statistics:\n",
      "Number of training images: 60000\n",
      "Mean: 0.2860\n",
      "Std: 0.3530\n",
      "Var: 0.1246\n",
      "\n",
      "Applying calculated normalization values:\n",
      "Mean: 0.2860\n",
      "Std: 0.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 0.4588, Train Acc: 83.56%\n",
      "Val Loss: 0.3315, Val Acc: 87.96%\n",
      "Learning Rate: 0.001\n",
      "Epoch 2/20\n",
      "Train Loss: 0.3241, Train Acc: 88.27%\n",
      "Val Loss: 0.2411, Val Acc: 90.92%\n",
      "Learning Rate: 0.001\n",
      "Epoch 3/20\n",
      "Train Loss: 0.2868, Train Acc: 89.68%\n",
      "Val Loss: 0.2253, Val Acc: 91.12%\n",
      "Learning Rate: 0.001\n",
      "Epoch 4/20\n",
      "Train Loss: 0.2630, Train Acc: 90.63%\n",
      "Val Loss: 0.2050, Val Acc: 92.50%\n",
      "Learning Rate: 0.001\n",
      "Epoch 5/20\n",
      "Train Loss: 0.2483, Train Acc: 91.20%\n",
      "Val Loss: 0.2044, Val Acc: 92.46%\n",
      "Learning Rate: 0.001\n",
      "Epoch 6/20\n",
      "Train Loss: 0.2356, Train Acc: 91.60%\n",
      "Val Loss: 0.1917, Val Acc: 92.76%\n",
      "Learning Rate: 0.001\n",
      "Epoch 7/20\n",
      "Train Loss: 0.2242, Train Acc: 91.83%\n",
      "Val Loss: 0.1753, Val Acc: 93.58%\n",
      "Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    try:\n",
    "        model = main()\n",
    "        test_model(model, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        visualize_predictions(model, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    finally:\n",
    "        wandb.finish()  # 모든 작업이 끝난 후에 wandb 종료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지의 각 라벨에 대한 패턴이 유사하거나 그레이스케일 변환을 통해, 그 구분이 더욱 힘들어져 잘못 구분 하였다고 판단됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 후기\n",
    "\n",
    "resnet18을 imagenet으로 pretrained 된 모델을 로드하여 fashion mnist 데이터셋에 적합하게\n",
    "변경함으로써 더욱 많은 경험을 할 수 있었습니다. 특히 pretrained 된 모델이여서 어느정도 잘\n",
    "학습이 될것이라 예상하여 데이터 augmentation을 하지 않았는데, test accuracy가 원하는 수치만큼\n",
    "나오지 않아 의외라 생각하였습니다. 추후 augmentation을 진행하고 나서 원하는 accuracy가 나오는것을 보고\n",
    "역시 이러한 기술이 나온 배경이 명확하다라고 느끼게 되었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
