{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "# 본 과제 제출자는 현재 우분투 도커 환경에서 작업중이므로 다음과 같이 경로 설정\n",
    "BASE_PATH=\"/home/Deep-Learning-study\"\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)\n",
    "\n",
    "CURRENT_FILE_PATH = os.getcwd()\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "  os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _01_code._15_lstm_and_its_application.f_arg_parser import get_parser\n",
    "from _01_code._15_lstm_and_its_application.g_crypto_currency_regression_train_lstm import get_btc_krw_data\n",
    "#from _01_code._15_lstm_and_its_application.i_crypto_currency_classification_train_lstm import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def get_model():\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self, n_input, n_output):\n",
    "            super().__init__()\n",
    "            \n",
    "            # 메인 LSTM 레이어\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=n_input,\n",
    "                hidden_size=1024,  # hidden size 증가\n",
    "                num_layers=3,      # 3개의 layer\n",
    "                dropout=0.1,       # dropout 추가\n",
    "                batch_first=True,\n",
    "                bidirectional=True # 양방향 LSTM\n",
    "            )\n",
    "            \n",
    "            # 분류를 위한 FC 레이어\n",
    "            self.fc_layers = nn.Sequential(\n",
    "                nn.LayerNorm(2048),  # bidirectional이므로 hidden_size * 2\n",
    "                nn.Linear(2048, 512),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(0.1),\n",
    "                \n",
    "                nn.LayerNorm(512),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(0.1),\n",
    "                \n",
    "                nn.LayerNorm(128),\n",
    "                nn.Linear(128, n_output),  # n_output=2 for binary classification\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            self.lstm.flatten_parameters()  # CUDA 성능 최적화\n",
    "            x, _ = self.lstm(x)\n",
    "            x = x[:, -1, :]  # 마지막 시퀀스의 출력만 사용\n",
    "            x = self.fc_layers(x)\n",
    "            return x  # CrossEntropyLoss를 사용할 것이므로 softmax는 여기서 적용하지 않음\n",
    "\n",
    "    my_model = MyModel(n_input=5, n_output=2)\n",
    "    return my_model\n",
    "\n",
    "# Args 클래스도 classification task에 맞게 수정\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.wandb = True\n",
    "        self.batch_size = 32       # classification은 regression보다 큰 배치 사이즈가 효과적일 수 있음\n",
    "        self.epochs = 300\n",
    "        self.learning_rate = 1e-3  # classification은 보통 더 큰 학습률 사용\n",
    "        self.weight_decay = 1e-4\n",
    "        self.validation_intervals = 1\n",
    "        self.early_stop_patience = 30\n",
    "        self.early_stop_delta = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_model):\n",
    "    # 테스트용 데이터로더만 가져옴 (분류 태스크용)\n",
    "    _, _, test_data_loader = get_btc_krw_data(is_regression=False)\n",
    "\n",
    "    # 모델을 평가 모드로 설정 (dropout, batch norm 등이 평가 모드로 변경됨)\n",
    "    test_model.eval()\n",
    "\n",
    "    # 정확도 계산을 위한 변수 초기화\n",
    "    num_corrects_test = 0      # 정확히 예측한 샘플 수\n",
    "    num_tested_samples = 0     # 전체 테스트 샘플 수\n",
    "\n",
    "    print(\"[TEST DATA]\")\n",
    "    # gradient 계산 비활성화 (메모리 사용량 감소, 연산 속도 향상)\n",
    "    with torch.no_grad():\n",
    "        # 테스트 데이터의 배치를 하나씩 처리\n",
    "        for test_batch in test_data_loader:\n",
    "            # 입력 데이터와 정답 레이블을 배치에서 추출\n",
    "            input_test, target_test = test_batch\n",
    "\n",
    "            # 모델을 통해 예측값 계산\n",
    "            output_test = test_model(input_test)\n",
    "\n",
    "            # 가장 높은 확률을 가진 클래스를 예측값으로 선택\n",
    "            predicted_test = torch.argmax(output_test, dim=1)\n",
    "            # 정답과 예측이 일치하는 개수 누적\n",
    "            num_corrects_test += torch.sum(torch.eq(predicted_test, target_test))\n",
    "\n",
    "            # 처리된 샘플 수 누적\n",
    "            num_tested_samples += len(input_test)\n",
    "\n",
    "        # 전체 정확도 계산 (백분율)\n",
    "        test_accuracy = 100.0 * num_corrects_test / num_tested_samples\n",
    "\n",
    "        # 전체 테스트 정확도 출력\n",
    "        print(f\"TEST RESULTS: {test_accuracy:6.3f}%\")\n",
    "\n",
    "        # 각 샘플별 예측 결과 출력\n",
    "        for idx, (output, target) in enumerate(zip(output_test, target_test)):\n",
    "            # 결과 출력 포맷:\n",
    "            # 인덱스: 예측 클래스 <--> 실제 클래스\n",
    "            print(\"{0:2}: {1:6,.2f} <--> {2:6,.2f}\".format(\n",
    "                idx,                            # 데이터 포인트 인덱스\n",
    "                torch.argmax(output).item(),    # 예측한 클래스 (0: 하락, 1: 상승)\n",
    "                target.item()                   # 실제 클래스\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # 현재 시간을 문자열로 변환 (실행 식별자로 사용)\n",
    "    run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    # wandb 설정을 위한 하이퍼파라미터 딕셔너리 생성\n",
    "    config = {\n",
    "        'epochs': args.epochs,                    # 총 학습 에폭 수\n",
    "        'batch_size': args.batch_size,           # 미니배치 크기\n",
    "        'validation_intervals': args.validation_intervals,  # 검증 수행 주기\n",
    "        'learning_rate': args.learning_rate,      # 학습률\n",
    "        'early_stop_patience': args.early_stop_patience,  # 조기 종료 인내 횟수\n",
    "        'early_stop_delta': args.early_stop_delta,  # 조기 종료 임계값\n",
    "    }\n",
    "\n",
    "    # wandb 프로젝트 초기화 (테스트 모드)\n",
    "    project_name = \"lstm_classification_btc_krw\"\n",
    "    wandb.init(\n",
    "        mode=\"disabled\",                          # 테스트 시에는 wandb 비활성화\n",
    "        project=project_name,                     # 프로젝트 이름\n",
    "        notes=\"btc_krw experiment with lstm\",     # 실험 설명\n",
    "        tags=[\"lstm\", \"regression\", \"btc_krw\"],   # 관련 태그\n",
    "        name=run_time_str,                       # 실행 이름 (시간 기반)\n",
    "        config=config                            # 설정값들\n",
    "    )\n",
    "\n",
    "    # 분류 모델 인스턴스 생성\n",
    "    test_model = get_model()\n",
    "\n",
    "    # 저장된 최신 모델 파일 경로 설정\n",
    "    latest_file_path = os.path.join(\n",
    "        CHECKPOINT_FILE_PATH, f\"{project_name}_checkpoint_2024-12-12_15-41-14.pt\"    # 최신 체크포인트 파일명\n",
    "    )\n",
    "    print(\"MODEL FILE: {0}\".format(latest_file_path))\n",
    "    \n",
    "    # 저장된 모델의 가중치를 CPU에 로드\n",
    "    test_model.load_state_dict(\n",
    "        torch.load(latest_file_path, map_location=torch.device('cpu'))\n",
    "    )\n",
    "\n",
    "    # 테스트 수행\n",
    "    test(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: /home/Deep-Learning-study/_02_homeworks/hw4/checkpoints/lstm_classification_btc_krw_checkpoint_2024-12-12_15-41-14.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_114449/3095837839.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(latest_file_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST DATA]\n",
      "TEST RESULTS: 53.333%\n",
      " 0:   1.00 <-->   0.00\n",
      " 1:   1.00 <-->   1.00\n",
      " 2:   1.00 <-->   0.00\n",
      " 3:   1.00 <-->   1.00\n",
      " 4:   1.00 <-->   1.00\n",
      " 5:   1.00 <-->   0.00\n",
      " 6:   1.00 <-->   1.00\n",
      " 7:   1.00 <-->   0.00\n",
      " 8:   1.00 <-->   1.00\n",
      " 9:   1.00 <-->   0.00\n",
      "10:   1.00 <-->   0.00\n",
      "11:   1.00 <-->   0.00\n",
      "12:   1.00 <-->   1.00\n",
      "13:   1.00 <-->   1.00\n",
      "14:   1.00 <-->   1.00\n",
      "15:   1.00 <-->   1.00\n",
      "16:   1.00 <-->   0.00\n",
      "17:   1.00 <-->   0.00\n",
      "18:   1.00 <-->   1.00\n",
      "19:   1.00 <-->   0.00\n",
      "20:   1.00 <-->   0.00\n",
      "21:   1.00 <-->   1.00\n",
      "22:   1.00 <-->   1.00\n",
      "23:   1.00 <-->   1.00\n",
      "24:   1.00 <-->   0.00\n",
      "25:   1.00 <-->   0.00\n",
      "26:   1.00 <-->   1.00\n",
      "27:   1.00 <-->   0.00\n",
      "28:   1.00 <-->   1.00\n",
      "29:   1.00 <-->   1.00\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    if 'ipykernel' in sys.modules:  # Jupyter Notebook에서 실행 중인지 확인\n",
    "        # Jupyter에서 실행할 때는 기본값 사용\n",
    "        args = Args()\n",
    "    else:\n",
    "        # 일반 Python 스크립트로 실행할 때는 argparse 사용\n",
    "        parser = get_parser()\n",
    "        args = parser.parse_args()\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
